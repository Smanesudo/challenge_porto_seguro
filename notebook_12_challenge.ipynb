{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Porto Seguro kaggle challenge\n",
    "\n",
    "## 1. Data Description\n",
    "\n",
    "In this competition, you will predict the probability that an auto insurance policy holder files a claim.\n",
    "\n",
    "In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., `ind` , `reg`, `car`, `calc`). In addition, feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation. The target columns signifies whether or not a claim was filed for that policy holder.\n",
    "\n",
    "## 2. File descriptions\n",
    "\n",
    "- `train.csv` contains the training data, where each row corresponds to a policy holder, and the target columns signifies that a claim was filed.\n",
    "- `test.csv` contains the test data.\n",
    "\n",
    "## 3. Aim\n",
    "\n",
    "- Build a classifier using the training dataset that leads to a good ROC and Precision / Recall curve on the testing set\n",
    "- The notebook should describe your steps, explain what you do and should run entirely without bugs. It should contain some descriptive statistics and quick study, to understand some things about the data...\n",
    "- It must end with plots of the ROC and precision/recall curves obtained on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b5be0e2-19af-4cde-93c7-9a208107592f",
    "_uuid": "5a4a7c23af9158d476133201eb2267860815b7b0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use the path to your filename\n",
    "\n",
    "#Chemin Kenny\n",
    "path = ''\n",
    "\n",
    "#Chemin Mickaël\n",
    "#path = '/home/chopin/Bureau/M2MOdata/machine_learning/tp2challenge'\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes = df.shape[0]\n",
    "colonnes = df.shape[1]\n",
    "print(\"Le jeu de données de training contient {0} lignes et {1} colonnes\".format(lignes, colonnes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analyse exploratoire des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)\tEtude des données brutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.isnull()\n",
    "Nombre_de_donnees_manquantes=df.isna().sum()\n",
    "Nombre_de_donnees_manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucune donnée manquante n'a été détectée ici. Il n'y a donc que celles qui ont codées par la valeur -1. On relève donc les données manquantes en changeant les -1 en NaN et via le test isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees=df.replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nombre_de_donnees_manquantes=donnees.isna().sum()\n",
    "Nombre_de_donnees_manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons une liste des features ayant des données manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_manquantes=donnees.columns[donnees.isna().any()].tolist()\n",
    "val_manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons les données manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(donnees[val_manquantes],width_ratios=(10,1),figsize=(20,10),color=(0.3,0.4,0.5),fontsize=18,\\\n",
    "            sparkline=True,labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculons les pourcentages de données manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "donnees_copy = (Nombre_de_donnees_manquantes / len(donnees)) * 100 \n",
    "donnees_copy = donnees_copy.drop(donnees_copy[donnees_copy == 0].index).sort_values(ascending=False)[:30]\n",
    "# Rajouter une colonne avec le nombre de NaN avec pd.concat\n",
    "manquantes = pd.DataFrame({'Données manquantes en %' :donnees_copy})\n",
    "manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(donnees.dtypes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=donnees.pop(\"target\")\n",
    "X , y = donnees , target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Données binaires**\n",
    "- ps_ind_06_bin \n",
    "- ps_ind_07_bin \n",
    "- ps_ind_08_bin \n",
    "- ps_ind_09_bin\n",
    "- ps_ind_10_bin\n",
    "- ps_ind_11_bin \n",
    "- ps_ind_12_bin \n",
    "- ps_ind_13_bin\n",
    "- ps_ind_16_bin \n",
    "- ps_ind_17_bin \n",
    "- ps_ind_18_bin \n",
    "- ps_calc_15_bin\n",
    "- ps_calc_16_bin \n",
    "- ps_calc_17_bin \n",
    "- ps_calc_18_bin \n",
    "- ps_calc_19_bin\n",
    "- ps_calc_20_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.dtypes\n",
    "#X.describe()\n",
    "#X.corr()\n",
    "\n",
    "bin_col=[col for col in X.columns if '_bin' in col]\n",
    "X_bin=X.loc[:,bin_col]\n",
    "\n",
    "for col in bin_col:\n",
    "    donnees[col] = donnees[col].astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Données catégorielles**\n",
    "- ps_ind_02_cat\n",
    "- ps_ind_04_cat \n",
    "- ps_ind_05_cat \n",
    "- ps_car_01_cat\n",
    "- ps_car_02_cat\n",
    "- ps_car_03_cat\n",
    "- ps_car_04_cat \n",
    "- ps_car_05_cat \n",
    "- ps_car_06_cat \n",
    "- ps_car_07_cat\n",
    "- ps_car_08_cat \n",
    "- ps_car_09_cat \n",
    "- ps_car_10_cat \n",
    "- ps_car_11_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=[col for col in X.columns if '_cat' in col]\n",
    "X_cat=X.loc[:,cat_col]\n",
    "\n",
    "for col in cat_col:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Données continues**\n",
    "- ps_ind_01 \n",
    "- ps_ind_03 \n",
    "- ps_ind_14 \n",
    "- ps_ind_15 \n",
    "- ps_reg_01\n",
    "- ps_reg_02\n",
    "- ps_reg_03 \n",
    "- ps_car_11 \n",
    "- ps_car_12 \n",
    "- ps_car_13 \n",
    "- ps_car_14\n",
    "- ps_car_15 \n",
    "- ps_calc_01 \n",
    "- ps_calc_02 \n",
    "- ps_calc_03 \n",
    "- ps_calc_04\n",
    "- ps_calc_05 \n",
    "- ps_calc_06 \n",
    "- ps_calc_07 \n",
    "- ps_calc_08 \n",
    "- ps_calc_09\n",
    "- ps_calc_10 \n",
    "- ps_calc_11 \n",
    "- ps_calc_12 \n",
    "- ps_calc_13\n",
    "- ps_calc_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_col=[col for col in X.columns if col[-3:] not in ['bin', 'cat']]\n",
    "X_cont=X.loc[:,cont_col]\n",
    "X_cont2=X[cont_col]\n",
    "type(X_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Visualisation `pandas` + `seaborn` du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélation des features continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_float = X_cont.select_dtypes(include=['float64'])\n",
    "colormap = plt.cm.inferno\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.title('Corrélation Pearson des features continues', y=1.05, size=15)\n",
    "sns.heatmap(X_float.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélation des features discrètes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = X.select_dtypes(include=['int64'])\n",
    "colormap = plt.cm.inferno\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.title('Corrélation Pearson des features discrètes', y=1.05, size=15)\n",
    "sns.heatmap(X_int.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution des features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axes = plt.subplots(nrows=5,ncols=3,figsize=(16,16))\n",
    "for i , colname in enumerate(cat_col):\n",
    "    sns.countplot(colname,data=X_cat,ax=fig.axes[i])\n",
    "plt.tight_layout()\n",
    "fig.delaxes(axes[4][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axes = plt.subplots(nrows=5,ncols=4,figsize=(13,13))\n",
    "for i , colname in enumerate(bin_col):\n",
    "    sns.countplot(colname,data=X_bin,ax=fig.axes[i])\n",
    "plt.tight_layout()\n",
    "for i in range(1,4):\n",
    "    fig.delaxes(axes[4][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogrammes\n",
    "#g = sns.FacetGrid(X_cont, col=cont_col[0]) \n",
    "#g.map(sns.distplot, \"you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(X_cont.(X_cont.columns[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution de la variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "sns.despine(left=True)\n",
    "sns.countplot(x=y, data=X)\n",
    "\n",
    "plt.tight_layout()\n",
    "#donnees.target\n",
    "#Mettre les valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Préparation des données pour l'entraînement des classifieurs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression de features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les features ps_car_03_cat, ps_car_05_cat et ps_reg_03 ont trop de valeurs manquantes. On va donc les supprimer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = X_cat.shape[1]\n",
    "cont1 = X_cont.shape[1]\n",
    "dropfeat1 = X_cat.pop('ps_car_03_cat')\n",
    "dropfeat2 = X_cat.pop('ps_car_05_cat')\n",
    "dropfeat3 = X_cont.pop('ps_reg_03')\n",
    "cont_col.remove('ps_reg_03')\n",
    "cat2 = X_cat.shape[1]\n",
    "cont2 = X_cont.shape[1]\n",
    "print(\"On a bien supprimé \" + str(cat1-cat2+cont1-cont2)+ \" features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime également la colonne id (à cause de sa valeur prédictive nulle) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = X_cont.pop('id')\n",
    "cont_col.remove('id')\n",
    "X_cont.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplissage des données manquantes en remplaçant les NaN par la moyenne des valeurs de la colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remp = SimpleImputer(missing_values=np.NaN, strategy=\"mean\")\n",
    "\n",
    "X_cont['ps_car_11']=remp.fit_transform(X_cont[['ps_car_11']]).ravel()\n",
    "X_cont['ps_car_12']=remp.fit_transform(X_cont[['ps_car_12']]).ravel()\n",
    "X_cont['ps_car_14']=remp.fit_transform(X_cont[['ps_car_14']]).ravel()\n",
    "#donnees['ps_reg_03']=remp.fit_transform(donnees[['ps_reg_03']]).ravel()   VALEUR SUPPRIMEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirons les derniers NaN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_cont = X_cont.dropna()\n",
    "#X_cat = X_cat.dropna()\n",
    "#X_bin = X_bin.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des données catégorielles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "X_cat_bin = pd.get_dummies(X_cat, prefix_sep='#', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_bin.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrage et réduction des variables continues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_cont)\n",
    "X_cont = scaler.transform(X_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont = pd.DataFrame(X_cont, columns = cont_col)\n",
    "X_cont.describe()\n",
    "X_cont.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat((X_bin, X_cat_bin, X_cont), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On a retiré des données, donc la liste des indices de la dataframe n'est plus contigue. \n",
    "#On réinitialise cette liste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des données traitées "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise `pickle` pour enregistrer les données traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('données_traitées.pkl', 'wb') as f:\n",
    "    pkl.dump(X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
